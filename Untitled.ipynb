{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc42493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snap-stanford in c:\\users\\anika\\anaconda3\\lib\\site-packages (6.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install snap-stanford\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4843565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 54077\n",
      "Edges: 234793\n"
     ]
    }
   ],
   "source": [
    "import snap\n",
    "\n",
    "# Read data from the file\n",
    "file_path = \"soc-redditHyperlinks-title.tsv\"\n",
    "\n",
    "# Create a directed graph\n",
    "graph = snap.TNGraph.New()\n",
    "\n",
    "# Dictionary to store node IDs for each subreddit\n",
    "node_ids = {}\n",
    "\n",
    "# Read and process each line in the file\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "\n",
    "        # Extract source and target subreddits\n",
    "        source_subreddit = columns[0]\n",
    "        target_subreddit = columns[1]\n",
    "\n",
    "        # Add nodes to the graph if they don't exist\n",
    "        if source_subreddit not in node_ids:\n",
    "            source_id = graph.AddNode()\n",
    "            node_ids[source_subreddit] = source_id\n",
    "        else:\n",
    "            source_id = node_ids[source_subreddit]\n",
    "\n",
    "        if target_subreddit not in node_ids:\n",
    "            target_id = graph.AddNode()\n",
    "            node_ids[target_subreddit] = target_id\n",
    "        else:\n",
    "            target_id = node_ids[target_subreddit]\n",
    "\n",
    "        # Add directed edge\n",
    "        graph.AddEdge(source_id, target_id)\n",
    "\n",
    "# Print basic graph statistics\n",
    "print(\"Nodes: %d\" % graph.GetNodes())\n",
    "print(\"Edges: %d\" % graph.GetEdges())\n",
    "\n",
    "# Save the graph to a file (optional)\n",
    "snap.SaveEdgeList(graph, \"reddit_graph.txt\", \"Directed graph of Reddit hyperlinks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657edfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygraphviz\n",
      "  Using cached pygraphviz-1.11.zip (120 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (setup.py): started\n",
      "  Building wheel for pygraphviz (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pygraphviz\n",
      "Failed to build pygraphviz\n",
      "Installing collected packages: pygraphviz\n",
      "  Running setup.py install for pygraphviz: started\n",
      "  Running setup.py install for pygraphviz: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [48 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  creating build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  running egg_info\n",
      "  writing pygraphviz.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "  writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "  reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.png' under directory 'doc'\n",
      "  warning: no files found matching '*.txt' under directory 'doc'\n",
      "  warning: no files found matching '*.css' under directory 'doc'\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  no previously-included directories found matching 'doc\\build'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  running build_ext\n",
      "  building 'pygraphviz._graphviz' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Running setup.py install for pygraphviz did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [50 lines of output]\n",
      "  running install\n",
      "  C:\\Users\\Anika\\anaconda3\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "    warnings.warn(\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  creating build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-38\\pygraphviz\\tests\n",
      "  running egg_info\n",
      "  writing pygraphviz.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "  writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "  reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.png' under directory 'doc'\n",
      "  warning: no files found matching '*.txt' under directory 'doc'\n",
      "  warning: no files found matching '*.css' under directory 'doc'\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  no previously-included directories found matching 'doc\\build'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-38\\pygraphviz\n",
      "  running build_ext\n",
      "  building 'pygraphviz._graphviz' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "Encountered error while trying to install package.\n",
      "\n",
      "pygraphviz\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -etworkx (c:\\users\\anika\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc0e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 35778\n",
      "Edges: 137822\n"
     ]
    }
   ],
   "source": [
    "import snap\n",
    "\n",
    "# Read data from the file\n",
    "file_path = \"soc-redditHyperlinks-body.tsv\"\n",
    "\n",
    "# Create a directed graph\n",
    "graph = snap.TNGraph.New()\n",
    "\n",
    "# Dictionary to store node IDs for each subreddit\n",
    "node_ids = {}\n",
    "\n",
    "# Read and process each line in the file\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Split the line into columns\n",
    "        columns = line.strip().split(\"\\t\")\n",
    "\n",
    "        # Extract source and target subreddits\n",
    "        source_subreddit = columns[0]\n",
    "        target_subreddit = columns[1]\n",
    "\n",
    "        # Add nodes to the graph if they don't exist\n",
    "        if source_subreddit not in node_ids:\n",
    "            source_id = graph.AddNode()\n",
    "            node_ids[source_subreddit] = source_id\n",
    "        else:\n",
    "            source_id = node_ids[source_subreddit]\n",
    "\n",
    "        if target_subreddit not in node_ids:\n",
    "            target_id = graph.AddNode()\n",
    "            node_ids[target_subreddit] = target_id\n",
    "        else:\n",
    "            target_id = node_ids[target_subreddit]\n",
    "\n",
    "        # Add directed edge\n",
    "        graph.AddEdge(source_id, target_id)\n",
    "\n",
    "# Print basic graph statistics\n",
    "print(\"Nodes: %d\" % graph.GetNodes())\n",
    "print(\"Edges: %d\" % graph.GetEdges())\n",
    "\n",
    "# Save the graph to a file (optional)\n",
    "snap.SaveEdgeList(graph, \"reddit_graph_body.txt\", \"Directed graph of Reddit hyperlinks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbe1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = nx.DiGraph()\n",
    "\n",
    "for node in graph.Nodes():\n",
    "    nx_graph.add_node(node.GetId())\n",
    "\n",
    "for edge in graph.Edges():\n",
    "    nx_graph.add_edge(edge.GetSrcNId(), edge.GetDstNId())\n",
    "\n",
    "# Subsample the graph\n",
    "# (Adjust the fraction parameter based on your graph size)\n",
    "subsampled_graph = nx_graph.subgraph(list(nx_graph.nodes())[:100])\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(subsampled_graph)\n",
    "plt.figure(figsize=(10, 10))\n",
    "nx.draw(subsampled_graph, pos, with_labels=True, node_size=20, font_size=8, font_color=\"black\", node_color=\"skyblue\", arrowsize=4)\n",
    "\n",
    "# Save the layout to a file\n",
    "plt.savefig(\"reddit_graph.png\")\n",
    "\n",
    "# Display the graph using IPython\n",
    "Image(\"reddit_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c80fb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete\n",
      "The number of lines in 'processed_post_crosslinks_info.txt' is: 286561\n"
     ]
    }
   ],
   "source": [
    "# Read input file and process each line\n",
    "with open('post_crosslinks_info.tsv', 'r') as input_file:\n",
    "    lines = input_file.readlines()\n",
    "\n",
    "# Process each line and write to a temporary output file\n",
    "temp_output_filename = 'processed_post_crosslinks_info.txt'\n",
    "with open(temp_output_filename, 'w') as temp_output_file:\n",
    "    for line in lines:\n",
    "        processed_line = line.replace('T', ' T')\n",
    "        # Split the line based on tabs\n",
    "        parts = processed_line.split('\\t')\n",
    "        \n",
    "        # Process each part, keeping only the left-hand side of the equals sign\n",
    "        processed_parts = [part.split('=')[0] if '=' in part else part for part in parts]\n",
    "        \n",
    "        processed_line1 = '\\t'.join(processed_parts)\n",
    "        temp_output_file.write(processed_line1 + '\\n')  # Add a newline character\n",
    "\n",
    "print(\"Processing complete\")\n",
    "\n",
    "filename = 'processed_post_crosslinks_info.txt'\n",
    "\n",
    "# Open the file and count the number of lines\n",
    "with open(filename, 'r') as file:\n",
    "    line_count = sum(1 for line in file)\n",
    "\n",
    "print(f\"The number of lines in '{filename}' is: {line_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d963574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes: 35776\n",
      "Total Edges: 137821\n"
     ]
    }
   ],
   "source": [
    "import snap\n",
    "\n",
    "# Create a directed graph\n",
    "G = snap.TNGraph.New()\n",
    "\n",
    "with open('processed_post_crosslinks_info.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Split the data into lines\n",
    "lines = data.strip().split('\\n')\n",
    "\n",
    "# Mapping between subreddit names and node IDs\n",
    "subreddit_to_id = {}\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for line in lines:\n",
    "    parts = line.split('\\t')  # Change the separator to tab\n",
    "    source_subreddit, target_subreddit = parts[0], parts[1]\n",
    "\n",
    "    # Add nodes if they don't exist\n",
    "    if source_subreddit not in subreddit_to_id:\n",
    "        source_id = G.AddNode()\n",
    "        subreddit_to_id[source_subreddit] = source_id\n",
    "    else:\n",
    "        source_id = subreddit_to_id[source_subreddit]\n",
    "\n",
    "    if target_subreddit not in subreddit_to_id:\n",
    "        target_id = G.AddNode()\n",
    "        subreddit_to_id[target_subreddit] = target_id\n",
    "    else:\n",
    "        target_id = subreddit_to_id[target_subreddit]\n",
    "\n",
    "    # Add a directed edge from source to target subreddit\n",
    "    G.AddEdge(source_id, target_id)\n",
    "\n",
    "# Print the total number of nodes and edges\n",
    "print(\"Total Nodes:\", G.GetNodes())\n",
    "print(\"Total Edges:\", G.GetEdges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4507a306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes: 172988\n",
      "Total Edges: 573122\n"
     ]
    }
   ],
   "source": [
    "import snap\n",
    "import re\n",
    "\n",
    "# ENCRYPT COZ POST ID CAN ONLY BE INT\n",
    "\n",
    "def convert_to_integer(post_id):\n",
    "    base = 36  # 10 digits + 26 letters\n",
    "\n",
    "    # Remove leading and trailing single quotes if present\n",
    "    post_id = post_id.strip(\"'\")\n",
    "\n",
    "    # Convert each character to its corresponding integer value\n",
    "    int_values = [int(c, base) for c in post_id]\n",
    "\n",
    "    # Combine the integer values to get a unique integer for the whole string\n",
    "    result = 0\n",
    "    for value in int_values:\n",
    "        result = result * base + value\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Create a bipartite graph\n",
    "G = snap.TNEANet.New()\n",
    "\n",
    "# Load post crosslinks info\n",
    "with open('processed_post_crosslinks_info.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Split the data into lines\n",
    "lines = data.strip().split('\\n')\n",
    "\n",
    "# Mapping between community and user names and their node IDs\n",
    "community_to_id = {}\n",
    "user_to_id = {}\n",
    "\n",
    "# Add nodes and edges to the bipartite graph\n",
    "for line in lines:\n",
    "    parts = re.split(r'\\t|\\s', line)\n",
    "\n",
    "    # Extract values into variables\n",
    "    source_community = parts[0]\n",
    "    target_community = parts[1]\n",
    "    post_id_source = parts[2]\n",
    "    timestamp_source = parts[3] + \" \" + parts[4]  # Combine date and time\n",
    "    user = parts[5]\n",
    "    post_id_target = parts[6]\n",
    "    timestamp_target = parts[7] + \" \" + parts[8]  # Combine date and time\n",
    "    \n",
    "    # Add nodes if they don't exist\n",
    "    if source_community not in community_to_id:\n",
    "        source_community_id = G.AddNode()\n",
    "        community_to_id[source_community] = source_community_id\n",
    "    else:\n",
    "        source_community_id = community_to_id[source_community]\n",
    "\n",
    "    if user not in user_to_id:\n",
    "        user_id = G.AddNode()\n",
    "        user_to_id[user] = user_id\n",
    "    else:\n",
    "        user_id = user_to_id[user]\n",
    "\n",
    "    if target_community not in community_to_id:\n",
    "        target_community_id = G.AddNode()\n",
    "        community_to_id[target_community] = target_community_id\n",
    "    else:\n",
    "        target_community_id = community_to_id[target_community]\n",
    "\n",
    "    # Add edges\n",
    "    G.AddEdge(source_community_id, user_id)\n",
    "    G.AddEdge(user_id, target_community_id)\n",
    "\n",
    "# Load label info\n",
    "with open('label_info.tsv', 'r') as file:\n",
    "    label_info = file.read()\n",
    "\n",
    "# Split label info into lines\n",
    "label_lines = label_info.strip().split('\\n')\n",
    "\n",
    "# Add sentiment attribute to edges\n",
    "for label_line in label_lines:\n",
    "    parts = label_line.split()\n",
    "    if len(parts) != 3:\n",
    "        print(f\"Skipping label line: {label_line}\")\n",
    "        continue\n",
    "\n",
    "    post_id_from, post_id_to, sentiment = parts[0][1:-1], parts[1][:-1], parts[2]\n",
    "    # Convert alphanumeric post IDs to integers\n",
    "    post_id_from_int = convert_to_integer(post_id_from)\n",
    "    post_id_to_int = convert_to_integer(post_id_to)\n",
    "     \n",
    "    # Find edge IDs based on source and target node IDs\n",
    "    edge_id = G.GetEId(source_community_id, user_id)\n",
    "\n",
    "    # Map sentiment values to 1 and 0\n",
    "    sentiment_value = 1 if sentiment == 'burst' else 0\n",
    "\n",
    "    # Add sentiment attribute to edges\n",
    "    G.AddIntAttrDatE(edge_id, sentiment_value, \"sentiment\")\n",
    "\n",
    "# Print the total number of nodes and edges\n",
    "print(\"Total Nodes:\", G.GetNodes())\n",
    "print(\"Total Edges:\", G.GetEdges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82c56c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "started geenraring\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"started\")\n",
    "# Create a NetworkX graph from the SNAP graph\n",
    "nx_graph = nx.Graph()\n",
    "print(\"started geenraring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1923c20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started separating\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted separating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Separate nodes into different lists based on their types\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m user_nodes \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nx_graph\u001b[38;5;241m.\u001b[39mnodes() \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m user_to_id\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     11\u001b[0m community_nodes \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nx_graph\u001b[38;5;241m.\u001b[39mnodes() \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m community_to_id\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted plotting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted separating\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Separate nodes into different lists based on their types\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m user_nodes \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nx_graph\u001b[38;5;241m.\u001b[39mnodes() \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[43muser_to_id\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     11\u001b[0m community_nodes \u001b[38;5;241m=\u001b[39m [node \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nx_graph\u001b[38;5;241m.\u001b[39mnodes() \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m community_to_id\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarted plotting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Add nodes to the NetworkX graph\n",
    "for NI in G.Nodes():\n",
    "    nx_graph.add_node(NI.GetId())\n",
    "\n",
    "# Add edges to the NetworkX graph\n",
    "for EI in G.Edges():\n",
    "    nx_graph.add_edge(EI.GetSrcNId(), EI.GetDstNId())\n",
    "print(\"started separating\")\n",
    "# Separate nodes into different lists based on their types\n",
    "user_nodes = [node for node in nx_graph.nodes() if node in user_to_id.values()]\n",
    "community_nodes = [node for node in nx_graph.nodes() if node in community_to_id.values()]\n",
    "\n",
    "print(\"started plotting\")\n",
    "# Plot the graph with different colors for users and communities\n",
    "pos = nx.spring_layout(nx_graph)  # You can use different layout algorithms\n",
    "nx.draw_networkx_nodes(nx_graph, pos, nodelist=user_nodes, node_color='red', node_size=50)\n",
    "nx.draw_networkx_nodes(nx_graph, pos, nodelist=community_nodes, node_color='blue', node_size=50)\n",
    "nx.draw_networkx_edges(nx_graph, pos, width=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b3744441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Nodes: 172988\n",
      "Total Edges: 378691\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "\n",
    "# ENCRYPT COZ POST ID CAN ONLY BE INT\n",
    "\n",
    "def convert_to_integer(post_id):\n",
    "    base = 36  # 10 digits + 26 letters\n",
    "\n",
    "    # Remove leading and trailing single quotes if present\n",
    "    post_id = post_id.strip(\"'\")\n",
    "\n",
    "    # Convert each character to its corresponding integer value\n",
    "    int_values = [int(c, base) for c in post_id]\n",
    "\n",
    "    # Combine the integer values to get a unique integer for the whole string\n",
    "    result = 0\n",
    "    for value in int_values:\n",
    "        result = result * base + value\n",
    "\n",
    "    return result\n",
    "\n",
    "# Create a bipartite graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Load post crosslinks info\n",
    "with open('processed_post_crosslinks_info.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Split the data into lines\n",
    "lines = data.strip().split('\\n')\n",
    "\n",
    "# Mapping between community and user names and their node IDs\n",
    "community_to_id = {}\n",
    "user_to_id = {}\n",
    "community_counter = 0\n",
    "user_counter = 0\n",
    "\n",
    "# Add nodes and edges to the bipartite graph\n",
    "for line in lines:\n",
    "    parts = re.split(r'\\t|\\s', line)\n",
    "\n",
    "    # Extract values into variables\n",
    "    source_community = parts[0]\n",
    "    target_community = parts[1]\n",
    "    post_id_source = parts[2]\n",
    "    timestamp_source = parts[3] + \" \" + parts[4]  # Combine date and time\n",
    "    user = parts[5]\n",
    "    post_id_target = parts[6]\n",
    "    timestamp_target = parts[7] + \" \" + parts[8]  # Combine date and time\n",
    "    \n",
    "    # Assign unique identifiers for community and user names\n",
    "    if source_community not in community_to_id:\n",
    "        community_to_id[source_community] = f\"C{community_counter}\"\n",
    "        community_counter += 1\n",
    "    if target_community not in community_to_id:\n",
    "        community_to_id[target_community] = f\"C{community_counter}\"\n",
    "        community_counter += 1\n",
    "    if user not in user_to_id:\n",
    "        user_to_id[user] = f\"U{user_counter}\"\n",
    "        user_counter += 1\n",
    "\n",
    "    # Add nodes and edges\n",
    "    G.add_edge(community_to_id[source_community], user_to_id[user])\n",
    "    G.add_edge(user_to_id[user], community_to_id[target_community])\n",
    "\n",
    "# Load label info\n",
    "with open('label_info.tsv', 'r') as file:\n",
    "    label_info = file.read()\n",
    "\n",
    "# Split label info into lines\n",
    "label_lines = label_info.strip().split('\\n')\n",
    "\n",
    "# Add sentiment attribute to edges\n",
    "for label_line in label_lines:\n",
    "    parts = label_line.split()\n",
    "    if len(parts) != 3:\n",
    "        print(f\"Skipping label line: {label_line}\")\n",
    "        continue\n",
    "\n",
    "    post_id_from, post_id_to, sentiment = parts[0][1:-1], parts[1][:-1], parts[2]\n",
    "    # Convert alphanumeric post IDs to integers\n",
    "    post_id_from_int = convert_to_integer(post_id_from)\n",
    "    post_id_to_int = convert_to_integer(post_id_to)\n",
    "     \n",
    "    # Map sentiment values to 1 and 0\n",
    "    sentiment_value = 1 if sentiment == 'burst' else 0\n",
    "\n",
    "    # Add sentiment attribute to edges\n",
    "    G[community_to_id[source_community]][user_to_id[user]]['sentiment'] = sentiment_value\n",
    "\n",
    "# Print the total number of nodes and edges\n",
    "print(\"Total Nodes:\", G.number_of_nodes())\n",
    "print(\"Total Edges:\", G.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e3c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
